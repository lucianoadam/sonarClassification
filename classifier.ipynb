{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML mini project 1: Sonar Data\n",
    "\n",
    "In this project, we are given a small data set containing sonar scans and their corresponding labels. The task is to build a model to predict those labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Installing required modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout the course of this small project, we will need to utilize pandas, scikit-learn and numpy (Which gets installed automatically because it is required by pandas). Below is a small script to install the modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setuptools import setup\n",
    "\n",
    "setup(\n",
    "    name='your_project_name',\n",
    "    version='1.0',\n",
    "    install_requires=[\n",
    "        'numpy>=1.21.0,<2.0',\n",
    "        'pandas>=1.3.0,<2.0',\n",
    "        'scikit-learn>=1.0.0,<2.0'\n",
    "    ],\n",
    "    python_requires='>=3.8,<4.0'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first load the data into the script and see the labels we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "full_data: pd.DataFrame = pd.read_csv('./sonar.csv', header=None)\n",
    "\n",
    "print(\"Labels:\", str(full_data[60].unique()))\n",
    "full_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Proportion of non-zero data:\", str(full_data.iloc[:, :60].astype(pd.SparseDtype(\"int\", 0)).sparse.density))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know that the data set contains a total of 207 instances of sonar scans. Each instance contains 60 readings (floating point numbers) and their corresponding labels. Since this is a binary classification problem, it seems like Logistic Regression might be the best choice. On top of that, now that we saw that the data is not very sparse, we know that l1 regularization might not be the best choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting the Data and Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to the training is to separate the data from the labels as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "label_map: dict[str, np.uint8] = {'R': np.uint8(0), 'M': np.uint8(1)}\n",
    "\n",
    "data: pd.DataFrame = full_data.drop(columns=[60])\n",
    "labels: pd.Series = full_data[60].map(label_map)\n",
    "\n",
    "del full_data, label_map\n",
    "\n",
    "print(data.info(), end='\\n\\n')\n",
    "labels.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have done that, we need to split the data into a training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Defining a random seed for reproducible output\n",
    "SEED: int = 11062024\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.3, stratify=labels, random_state=SEED)\n",
    "\n",
    "del data, labels\n",
    "\n",
    "# Checking data integrity\n",
    "print(train_labels.value_counts(normalize=True), end='\\n\\n')\n",
    "print(test_labels.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now properly formatted, so we can proceed to model training. As stated before, the model of choice is Logistic Regression for this scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model: LogisticRegression = LogisticRegression(random_state=SEED, solver='liblinear')\n",
    "model.fit(train_data, train_labels)\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, just like that, the model is ready. Next we will test the fitted model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "train_prediction: np.ndarray = model.predict(train_data)\n",
    "\n",
    "print(classification_report(train_labels, train_prediction, target_names=['R', 'M']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model demonstrated strong performance on the training data, achieving metrics exceeding 80% across precision, recall, and F1-score for both classes. However, there is a noticeable discrepancy in the recall for class `R` (75%) compared to class `M` (87%). This indicates that the model has a higher rate of false negatives for class `R`, meaning it often fails to correctly identify samples belonging to this class. Such behavior may suggest that the model is biased toward predicting class `M`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Data Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction: np.ndarray = model.predict(test_data)\n",
    "\n",
    "print(classification_report(test_labels, test_prediction, target_names=['R', 'M']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model displayed moderate performance on the test data, achieving an overall accuracy of 76% and balanced metrics for both classes, with precision, recall, and F1-scores all around 76%. While the metrics for class `R` and class `M` are relatively close, there is a slight difference in recall, with class `R` achieving 72% compared to class `M` at 79%. \n",
    "\n",
    "This indicates that the model has a marginally higher rate of false negatives for class `R`, leading to missed predictions for this class. Given the smaller size of the test dataset, these variations might be influenced by sampling noise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
